{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM47ftXMM9ocMf7fGHrNFKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deltan2002/pytorch/blob/main/Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dujGZUZuR5xf"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3,requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEiwlmmvZ18V",
        "outputId": "f02bfd6b-e332-47f5-b225-3e1294df9d1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6041, -0.5312,  0.6766], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x + 2\n",
        "print(y)\n",
        "\n",
        "z = y*y*2\n",
        "print('z:',z)\n",
        "\n",
        "# z = z.mean()\n",
        "print('z mean:', z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6V4UN46Z8Ch",
        "outputId": "89106b9d-5d65-4aa2-8646-109d547d7d65"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3959, 1.4688, 2.6766], grad_fn=<AddBackward0>)\n",
            "z: tensor([ 3.8969,  4.3146, 14.3289], grad_fn=<MulBackward0>)\n",
            "z mean: tensor([ 3.8969,  4.3146, 14.3289], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([0.1, 1.0, 0.001],dtype=torch.float32)\n",
        "\n",
        "z.backward(vector) #dz/dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumLH9TqZ40-",
        "outputId": "b349bf47-7a73-4b83-e75e-f4a6bdf8da52"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.2113, 37.2090,  3.6331], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREVENTING GRADIENT HISTORY\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "\n",
        "x.requires_grad_(False)    #whenever a function has a trailing underscore, then that means it modifies in-place\n",
        "print(x)\n",
        "\n",
        "y = x.detach()\n",
        "print(y)\n",
        "\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ultbqOM2dtKJ",
        "outputId": "f74b577b-ab51-4956-fb24-26ad5fd322bd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6041, -0.5312,  0.6766])\n",
            "tensor([-0.6041, -0.5312,  0.6766])\n",
            "tensor([1.3959, 1.4688, 2.6766])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights * 3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5anWqunewV-",
        "outputId": "7cd6560a-444d-47e9-cac5-b5982818e0f6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever we want to calculate the gradients we must specify the **requires_grad=True**, then we can calucalte gradients by calling **backward()** function and before we move on to next iteration, we must empty our gradients by calling **weights.grad.zero_()**"
      ],
      "metadata": {
        "id": "TzIWptiuf1NR"
      }
    }
  ]
}