{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvYFOpZJDKhkrHbPyibh7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deltan2002/pytorch/blob/main/CIFAR10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "36Hnshcu7PpE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcYauY8g8jcv",
        "outputId": "bf7942c0-1e0a-4c85-f210-28ae4a15c25f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hper params\n",
        "\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "4-NXk_c28sDy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Load CIFAR10 dataset\n",
        "dataset has PILImage images of range [0,1].\n",
        "We transform them to Tensors of normalisedf range [-1,1]\n",
        "'''\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "     ])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size= batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUetm1nU8z2t",
        "outputId": "6238ae34-9fce-421b-d533-5581607438ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 75352250.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5) #(input rgb(3), output channel(6), kernel_size(5) )\n",
        "    self.pool = nn.MaxPool2d(2,2) #2x2 maxpooling\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qQYzGrc-kWb",
        "outputId": "32894228-1a9a-4c0f-c841-dcae2d1657a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    #origin shape: [4,3,32,32] = 4,3,1024 (batch_size, color channel, img_x, img_y)\n",
        "    #inut shape: 3 input channels, 6 ooutput channels, 5 kernel size\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criteria(outputs, labels)\n",
        "\n",
        "    #backward and optmize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if(i+1) % 2000  == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.3f}')\n",
        "print('Finished training')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxVCO-wq-yp-",
        "outputId": "1c54ea9c-d582-46b0-a19b-b315635c8009"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4], Step [2000/12500], Loss: 2.285\n",
            "Epoch [1/4], Step [4000/12500], Loss: 2.305\n",
            "Epoch [1/4], Step [6000/12500], Loss: 2.298\n",
            "Epoch [1/4], Step [8000/12500], Loss: 2.169\n",
            "Epoch [1/4], Step [10000/12500], Loss: 2.169\n",
            "Epoch [1/4], Step [12000/12500], Loss: 2.036\n",
            "Epoch [2/4], Step [2000/12500], Loss: 2.450\n",
            "Epoch [2/4], Step [4000/12500], Loss: 1.869\n",
            "Epoch [2/4], Step [6000/12500], Loss: 1.997\n",
            "Epoch [2/4], Step [8000/12500], Loss: 2.131\n",
            "Epoch [2/4], Step [10000/12500], Loss: 1.801\n",
            "Epoch [2/4], Step [12000/12500], Loss: 2.286\n",
            "Epoch [3/4], Step [2000/12500], Loss: 2.079\n",
            "Epoch [3/4], Step [4000/12500], Loss: 1.861\n",
            "Epoch [3/4], Step [6000/12500], Loss: 1.573\n",
            "Epoch [3/4], Step [8000/12500], Loss: 1.519\n",
            "Epoch [3/4], Step [10000/12500], Loss: 1.789\n",
            "Epoch [3/4], Step [12000/12500], Loss: 1.553\n",
            "Epoch [4/4], Step [2000/12500], Loss: 1.346\n",
            "Epoch [4/4], Step [4000/12500], Loss: 1.794\n",
            "Epoch [4/4], Step [6000/12500], Loss: 0.788\n",
            "Epoch [4/4], Step [8000/12500], Loss: 1.176\n",
            "Epoch [4/4], Step [10000/12500], Loss: 1.312\n",
            "Epoch [4/4], Step [12000/12500], Loss: 1.085\n",
            "Finished training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct =[0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    #max returns (value, index)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    predicted = predicted.to(device)\n",
        "\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] +=1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy: {acc}%')\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]} : {acc}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_z6rn2RAdWL",
        "outputId": "acdf61f2-2615-430f-c6a9-20dc96692f44"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 42.64%\n",
            "Accuracy of plane : 42.1%\n",
            "Accuracy of car : 52.1%\n",
            "Accuracy of bird : 14.0%\n",
            "Accuracy of cat : 22.5%\n",
            "Accuracy of deer : 39.9%\n",
            "Accuracy of dog : 35.3%\n",
            "Accuracy of frog : 50.4%\n",
            "Accuracy of horse : 69.0%\n",
            "Accuracy of ship : 38.2%\n",
            "Accuracy of truck : 62.9%\n"
          ]
        }
      ]
    }
  ]
}